{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\49179\\\\Desktop\\\\Food_image_classification\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\49179\\\\Desktop\\\\Food_image_classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    loss_function: torch.nn.Module\n",
    "    learning_rate: float\n",
    "    epochs: int\n",
    "    device: str\n",
    "    classes: int\n",
    "    schedular_params: dict\n",
    "    bentoml_model_name: str\n",
    "    train_transform_key: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from Food_Classification.config.configuration import ConfigurationManager\n",
    "from Food_Classification.constants import *\n",
    "from Food_Classification.utils.common import read_yaml, create_directory\n",
    "from Food_Classification.entity.config_entity import DataTransformConfig\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path= CONFIG_FILE_PATH,\n",
    "                 params_file_path= PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        \n",
    "        config = self.config.model_training\n",
    "        create_directory([config.root_dir])\n",
    "        \n",
    "        TrainConfig = TrainingConfig(root_dir= config.root_dir,\n",
    "                                     loss_function=LOSS_FUNCTION(),\n",
    "                                     learning_rate= self.params.LEARNING_RATE,\n",
    "                                     epochs= self.params.EPOCHS,\n",
    "                                     device= self.params.DEVICE,\n",
    "                                     classes= self.params.CLASSES,\n",
    "                                     schedular_params= {\"step_size\": self.params.STEP_SIZE,\n",
    "                                                        \"gamma\": self.params.GAMMA},\n",
    "                                     bentoml_model_name= \"Food_Classification_Model\",\n",
    "                                     train_transform_key= \"TRAIN_TRANSFORM_KEY\")\n",
    "        \n",
    "        return TrainConfig\n",
    "    \n",
    "    def get_DataTransformConfig(self) -> DataTransformConfig:\n",
    "        config = self.config.data_transforms\n",
    "        create_directory([config.root_dir])\n",
    "        train_dir = os.path.join(self.config.data_ingestion.unzip_dir,'food_40_percent','train')\n",
    "        test_dir = os.path.join(self.config.data_ingestion.unzip_dir,'food_40_percent','test')\n",
    "        train_transformed_file = Path(config.TRAIN_TRANSFORMS_FILE)\n",
    "        test_transformed_file = Path(config.TEST_TRANSFORMS_FILE)\n",
    "\n",
    "        TransformationConfig = DataTransformConfig(root_dir= config.root_dir,\n",
    "                                                   train_dir=Path(train_dir),\n",
    "                                                   test_dir=Path(test_dir),\n",
    "                                                    train_transforms_file=train_transformed_file,\n",
    "                                                    test_transforms_file=test_transformed_file,\n",
    "                                                   color_transform={\"brightness\":BRIGHTNESS,\n",
    "                                                                    \"contrast\":CONTRAST,\n",
    "                                                                    \"saturation\":SATURATION,\n",
    "                                                                    \"hue\":HUE},\n",
    "                                                    spatial_transform= {'vertical_flip': VERTICLE_FLIP,\n",
    "                                                                        'resize': RESIZE,\n",
    "                                                                        'center_crop': CENTER_CROP,\n",
    "                                                                        'rotation': RANDOMROTATION\n",
    "                                                                        },\n",
    "                                                    normalize= {'mean': NORMALIZE_MEAN,\n",
    "                                                                'std': NORMALIZE_STD},\n",
    "                                                    data_loader_params={'batch_size': self.params.BATCH_SIZE,\n",
    "                                                                        'shuffle': self.params.SHUFFLE,\n",
    "                                                                        'num_workers': NUM_WORKERS,\n",
    "                                                                        'pin_memory': PIN_MEMORY,\n",
    "                                                                         })\n",
    "        return TransformationConfig\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src\\Food_Classification\\components\\model_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src\\Food_Classification\\components\\model_trainer.py\n",
    "#import torch\n",
    "#import joblib\n",
    "#import bentoml\n",
    "#from Food_Classification.entity.artifact_entity import DataTransformationArtifact, ModelTrainingArtifact\n",
    "#from tqdm import tqdm\n",
    "#from torch.optim.lr_scheduler import StepLR, _LRScheduler\n",
    "#from Food_Classification import logger\n",
    "#from Food_Classification.config.configuration import ConfigurationManager\n",
    "\n",
    "\n",
    "class Model_Training:\n",
    "    def __init__(self, config: TrainingConfig, transformation_Artifacts: DataTransformationArtifact):\n",
    "        self.config = config\n",
    "        self.transformation_Artifacts: DataTransformationArtifact = (transformation_Artifacts)\n",
    "        self.model = torch.load(Path(\"artifacts/prepare_base_model/base_model_updated.pth\"),map_location=torch.device(self.config.device))\n",
    "\n",
    "    def train_step(self,optimizer: torch.optim.Optimizer):\n",
    "        '''To train model\n",
    "        input: model, device, train_dataloader, optimizer, epoch\n",
    "        output: loss, accuracy'''\n",
    "        logger.info(\"Model training train step started\")\n",
    "        try:\n",
    "            self.model.train()\n",
    "\n",
    "            train_loss, train_accuracy =0,0\n",
    "            ProgressBar = tqdm(self.transformation_Artifacts.transformed_train_object)\n",
    "\n",
    "\n",
    "            for batch, (data, label) in enumerate(ProgressBar):\n",
    "                data, label = data.to(self.config.device), label.to(self.config.device)\n",
    "\n",
    "                #forward pass\n",
    "                y_pred = self.model(data)\n",
    "\n",
    "                # Calculate the loss \n",
    "                loss = self.config.loss_function(y_pred, label)\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                #setting optimizer to zero grad\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # Calculate the accuracy\n",
    "                target_predict = torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
    "                train_accuracy += (target_predict == label).sum().item()/len(y_pred)\n",
    "\n",
    "            train_loss = train_loss/len(self.transformation_Artifacts.transformed_train_object)\n",
    "            train_accuracy = train_accuracy/len(self.transformation_Artifacts.transformed_train_object)\n",
    "            ProgressBar.set_description(f\"Train_loss: {train_loss} | Train_accuracy: {train_accuracy}|\")\n",
    "\n",
    "            logger.info(\"Train step is finished\")\n",
    "              \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def test_step(self):\n",
    "        '''To test model\n",
    "        input: model, device, test_dataloader\n",
    "        output: loss, accuracy'''\n",
    "        logger.info(\"Model training test step started\")\n",
    "\n",
    "        try:\n",
    "            self.model.eval()\n",
    "\n",
    "            test_loss, test_accuracy =0,0\n",
    "            ProgressBar = tqdm(self.transformation_Artifacts.transformed_test_object)\n",
    "            with torch.inference_mode():\n",
    "            \n",
    "                for batch, (data, label) in enumerate(ProgressBar):\n",
    "                    data, label = data.to(self.config.device), label.to(self.config.device)\n",
    "\n",
    "                    label_pred = self.model(data)\n",
    "\n",
    "                    #calcuate the loss\n",
    "                    loss = self.config.loss_function(label_pred, label)\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "                    # Calculate the accuracy\n",
    "                    target_predict = torch.argmax(torch.softmax(label_pred,dim=1),dim=1)\n",
    "                    test_accuracy += (target_predict == label).sum().item()/len(label_pred)\n",
    "\n",
    "            test_loss = test_loss/len(self.transformation_Artifacts.transformed_test_object)\n",
    "            test_accuracy = test_accuracy/len(self.transformation_Artifacts.transformed_test_object)\n",
    "            logger.info(\"Test step finished\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def initiate_Model_training(self) -> ModelTrainingArtifact:\n",
    "        try:\n",
    "            logger.info(\"Model training started\")\n",
    "            model: torch.nn.Module = self.model.to(self.config.device)\n",
    "            optimizer: torch.optim.Optimizer = torch.optim.Adam(model.parameters(),lr = self.config.learning_rate)\n",
    "            schedular: _LRScheduler = StepLR(optimizer=optimizer,\n",
    "                                             **self.config.schedular_params)\n",
    "            \n",
    "            for epoch in range(1,self.config.epochs+1):\n",
    "                logger.info(f\"Epoch: {epoch}\")\n",
    "                self.train_step(optimizer=optimizer)\n",
    "                optimizer.step()\n",
    "                schedular.step()\n",
    "                self.test_step()\n",
    "\n",
    "            \n",
    "            trained_model_path = os.path.join(self.config.root_dir, \"trained_model.pth\")\n",
    "            torch.save(model, trained_model_path)\n",
    "\n",
    "            train_trans_obj  = joblib.load(self.transformation_Artifacts.trained_transformed_file)\n",
    "            bentoml.pytorch.save_model(name= self.config.bentoml_model_name,\n",
    "                                       model=model,\n",
    "                                       custom_objects={self.config.train_transform_key: train_trans_obj}\n",
    "                                       )\n",
    "            \n",
    "            \n",
    "            model_training_artifact: ModelTrainingArtifact = ModelTrainingArtifact(\n",
    "                trained_model_path= trained_model_path)\n",
    "            \n",
    "            logger.info(\"MOdel training Complete\")\n",
    "            return model_training_artifact\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-20 14:20:30,944: INFO: common: yaml file config\\config.yaml loaded successfully]\n",
      "[2024-05-20 14:20:30,946: INFO: common: yaml file params.yaml loaded successfully]\n",
      "[2024-05-20 14:20:30,947: INFO: common: directory artifacts created successfully]\n",
      "[2024-05-20 14:20:30,948: INFO: common: directory artifacts/data_transforms created successfully]\n",
      "[2024-05-20 14:20:30,949: INFO: data_transformation: Data Transformation started]\n",
      "[2024-05-20 14:20:30,953: INFO: data_transformation: transform pickle file created]\n",
      "[2024-05-20 14:20:30,954: INFO: data_transformation: Data Loading started]\n",
      "[2024-05-20 14:20:30,994: INFO: data_transformation: Data Transformation completed]\n",
      "[2024-05-20 14:20:31,016: INFO: common: directory artifacts/model_training created successfully]\n",
      "[2024-05-20 14:20:31,222: INFO: 3185675670: Model training started]\n",
      "[2024-05-20 14:20:31,225: INFO: 3185675670: Epoch: 1]\n",
      "[2024-05-20 14:20:31,226: INFO: 3185675670: Model training train step started]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:55<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-20 14:21:26,664: INFO: 3185675670: Train step is finished]\n",
      "[2024-05-20 14:21:26,665: INFO: 3185675670: Model training test step started]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 63/63 [00:39<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-20 14:22:05,978: INFO: 3185675670: Test step finished]\n",
      "[2024-05-20 14:22:06,128: INFO: pytorch: Using the default model signature for PyTorch ({'__call__': {'batchable': False}}) for model \"Food_Classification_Model\".]\n",
      "[2024-05-20 14:22:06,128: WARNING: tag: Converting 'Food_Classification_Model' to lowercase: 'food_classification_model'.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-20 14:22:07,010: INFO: _client: HTTP Request: POST https://t.bentoml.com \"HTTP/1.1 200 OK\"]\n",
      "[2024-05-20 14:22:07,011: INFO: 3185675670: MOdel training Complete]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelTrainingArtifact(trained_model_path='artifacts/model_training\\\\trained_model.pth')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Food_Classification.entity.config_entity import DataTransformConfig\n",
    "from Food_Classification.components.data_transformation import DataTransformation\n",
    "#from Food_Classification.config.configuration import ConfigurationManager\n",
    "config = ConfigurationManager()\n",
    "tran = config.get_DataTransformConfig()\n",
    "transfom = DataTransformation(tran)\n",
    "transfom_artifact = transfom.initiate_datatransfrom()\n",
    "training_config = config.get_training_config()\n",
    "training = Model_Training(config=training_config, transformation_Artifacts= transfom_artifact)\n",
    "training.initiate_Model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
