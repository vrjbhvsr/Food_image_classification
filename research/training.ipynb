{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\49179\\\\Desktop\\\\Food_image_classification\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\49179\\\\Desktop\\\\Food_image_classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class training_config:\n",
    "    root_dir: Path\n",
    "    model_path: Path\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    device: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Food_Classification.utils.common import read_yaml, create_directory\n",
    "from Food_Classification.constants import *\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_file_path= CONFIG_FILE_PATH,\n",
    "                 params_file_path = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        create_directory([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> training_config:\n",
    "        config = self.config.model_training\n",
    "        create_directory([config.root_dir])\n",
    "        self.model_path = self.config.prepare_base_model.updated_base_model\n",
    "        Training_Config = training_config(root_dir= config.root_dir,\n",
    "                                          model_path= self.model_path,\n",
    "                                          epochs= self.params.EPOCHS,\n",
    "                                          batch_size= self.params.BATCH_SIZE,\n",
    "                                          learning_rate= self.params.LEARNING_RATE,\n",
    "                                          device=self.params.DEVICE\n",
    "                                         )\n",
    "\n",
    "\n",
    "        return Training_Config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "class Model_training:\n",
    "    def __init__(self, config: training_config, train_dataloader: DataLoader, test_dataloader: DataLoader, loss_function: torch.nn.Module, writer: SummaryWriter):\n",
    "        self.config = config\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.model = torch.load(self.config.model_path,map_location=torch.device(self.config.device))\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = self.config.optimizer\n",
    "        self.writer = writer\n",
    "    \n",
    "    def train_step(self,train_dataloader):\n",
    "        model = self.model\n",
    "        try:\n",
    "            # Initiate model training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_acc= 0\n",
    "            progress = tqdm(train_dataloader)\n",
    "            # Looping through batches\n",
    "            for batch, (data, target) in enumerate(progress):\n",
    "                # Setting up data into device\n",
    "                data, target = data.to(self.config.device), target.to(self.config.device)\n",
    "\n",
    "                # forward propogation\n",
    "                target_pred = model(data)\n",
    "\n",
    "                # Calculating loss\n",
    "                loss = self.loss_function(target_pred, target)\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                # setting optimizer to zero gradient\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # backward propogation\n",
    "                loss.backward()\n",
    "                \n",
    "                # updating weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "                \n",
    "                # Calculating accuracy\n",
    "                target_pred_class = torch.argmax(torch.softmax(target_pred, dim=1), dim=1) \n",
    "                train_acc += (target_pred_class == target).sum().item() / len(target_pred)\n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "            train_acc /= len(train_dataloader)\n",
    "\n",
    "            progress.set_description(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "            return train_loss, train_acc\n",
    "                \n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def test_step(self, test_dataloader):\n",
    "        model = self.model\n",
    "        try:\n",
    "            # Intiatig model evaluation\n",
    "            model.eval()\n",
    "\n",
    "            test_loss, test_acc = 0,0\n",
    "            progress = tqdm(test_dataloader)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                for batch, (data, target) in enumerate(progress):\n",
    "                    data, target = data.to(self.config.device), target.to(self.config.device)\n",
    "\n",
    "                    # forward propogation\n",
    "                    target_pred = model(data)\n",
    "\n",
    "                    # Calculating Loss\n",
    "                    loss = self.loss_function(target_pred, target)\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "                    # calculating Accuracy\n",
    "                    target_pred_class = torch.argmax(target_pred, dim =1)\n",
    "                    test_acc = (target_pred_class == target).sum().item()/len(target_pred)\n",
    "\n",
    "                test_loss /= len(test_dataloader)\n",
    "                test_acc /= len(test_dataloader)\n",
    "\n",
    "                progress.set_description(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "                return test_loss, test_acc\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def initiate_training(self):\n",
    "        model = self.config.model_path\n",
    "        results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "        }\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            train_loss, train_acc = self.train_step(self.train_dataloader)\n",
    "            test_loss, test_acc = self.test_step(self.test_dataloader)\n",
    "\n",
    "            # Update results dictionary\n",
    "            results[\"train_loss\"].append(train_loss)\n",
    "            results[\"train_acc\"].append(train_acc)\n",
    "            results[\"test_loss\"].append(test_loss)\n",
    "            results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "         ### Experiment tracking\n",
    "        self.writer.add_scalars(main_tag=\"Loss\",\n",
    "                            tag_scalar_dict = {\"Train_loss\" : self.train_loss,\n",
    "                                                \"Test_loss\" : self.test_loss},\n",
    "                            global_step= epoch\n",
    "                            )\n",
    "        self.writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                            tag_scalar_dict = {\"Train_acc\" : self.train_acc,\n",
    "                                                \"Test_acc\" : self.test_acc},\n",
    "                            global_step= epoch\n",
    "                            )\n",
    "\n",
    "        self.writer.add_graph(model=model,\n",
    "        input_to_model = torch.randn(32,3,224,224).to(self.config.device))\n",
    "    # Return the filled results at the end of the epochs\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-06 22:53:15,462: INFO: common: yaml file config\\config.yaml loaded successfully]\n",
      "[2024-05-06 22:53:15,467: INFO: common: yaml file params.yaml loaded successfully]\n",
      "[2024-05-06 22:53:15,470: INFO: common: directory artifacts created successfully]\n",
      "[2024-05-06 22:53:15,471: INFO: common: directory artifacts/data_transforms created successfully]\n",
      "[2024-05-06 22:53:15,472: INFO: data_transformation: Initiating data transformation]\n",
      "[2024-05-06 22:53:15,473: INFO: data_transformation: Transforming train data]\n",
      "[2024-05-06 22:53:15,474: INFO: data_transformation: Transforming test data]\n",
      "[2024-05-06 22:53:15,479: INFO: data_transformation: creating_dataloaders]\n",
      "[2024-05-06 22:53:15,534: INFO: data_transformation: DataLoaders created]\n",
      "[2024-05-06 22:53:15,535: INFO: common: directory artifacts/prepare_tensorboard created successfully]\n",
      "[2024-05-06 22:53:15,536: INFO: common: directory artifacts/prepare_tensorboard/tensorboard_log_dir created successfully]\n",
      "[2024-05-06 22:53:15,542: INFO: common: directory artifacts/prepare_base_model created successfully]\n",
      "[2024-05-06 22:53:16,723: INFO: common: directory artifacts/model_training created successfully]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/188 [01:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'zero_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m train_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_training_config()\n\u001b[0;32m     16\u001b[0m training \u001b[38;5;241m=\u001b[39m Model_training(train_config, train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, test_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader, loss_function\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),writer\u001b[38;5;241m=\u001b[39mwriter)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 107\u001b[0m, in \u001b[0;36mModel_training.initiate_training\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m    104\u001b[0m }\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m--> 107\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataloader)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Update results dictionary\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 62\u001b[0m, in \u001b[0;36mModel_training.train_step\u001b[1;34m(self, train_dataloader)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_acc\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m, in \u001b[0;36mModel_training.train_step\u001b[1;34m(self, train_dataloader)\u001b[0m\n\u001b[0;32m     36\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# setting optimizer to zero gradient\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# backward propogation\u001b[39;00m\n\u001b[0;32m     42\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'zero_grad'"
     ]
    }
   ],
   "source": [
    "from Food_Classification.components.data_transformation import data_transformation\n",
    "from Food_Classification.components.tensorboard import preparetensorboard\n",
    "from Food_Classification.components.prepare_base_model import PrepareBaseModel\n",
    "from Food_Classification.config.configuration import ConfigurationManager\n",
    "config = ConfigurationManager()\n",
    "transformation_config = config.get_data_transform_config()\n",
    "transform = data_transformation(config=transformation_config)\n",
    "train_dataloader, test_dataloader, class_names = transform.initiate_data_transformation()\n",
    "tensorboard = preparetensorboard(config=config.get_tensorboard_config())\n",
    "writer = tensorboard.get_summary_writer()\n",
    "prepare_base_model_config = config.get_base_model_config()\n",
    "prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "prepare_base_model.get_base_model()\n",
    "prepare_base_model.update_base_model()\n",
    "train_config = config.get_training_config()\n",
    "training = Model_training(train_config, train_dataloader=train_dataloader, test_dataloader=test_dataloader, loss_function= torch.nn.CrossEntropyLoss(),writer=writer)\n",
    "training.initiate_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
